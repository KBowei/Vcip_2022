import torch
from torch.autograd import Variable
import glob as gb
from PIL import Image
import numpy as np
from torch.nn import functional as F


model_qps = range(7) # 7 MSE models
model_lambdas = [0.4, 0.25, 0.16, 0.10, 0.0625, 0.039, 0.024]
qp_shifts = [[6.5, 6.5625, 6.625, 6.6875, 6.75, 6.8125, 6.875, 6.9375, 7.0, 7.0625, 7.125, 7.1875, 7.25, 7.3125, 7.375, 7.4375, 7.5, 7.5625, 7.625, 7.6875, 7.75, 7.8125, 7.875, 7.9375, 8.0, 8.0625, 8.125, 8.1875, 8.25, 8.3125, 8.375, 8.4375, 8.5, 8.5625, 8.625, 8.6875, 8.75, 8.8125, 8.875, 8.9375, 9.0, 9.0625, 9.125, 9.1875, 9.25, 9.3125, 9.375, 9.4375, 9.5],
 [6.5, 6.5625, 6.625, 6.6875, 6.75, 6.8125, 6.875, 6.9375, 7.0, 7.0625, 7.125, 7.1875, 7.25, 7.3125, 7.375, 7.4375, 7.5, 7.5625, 7.625, 7.6875, 7.75, 7.8125, 7.875, 7.9375, 8.0, 8.0625, 8.125, 8.1875, 8.25, 8.3125, 8.375, 8.4375, 8.5, 8.5625, 8.625, 8.6875, 8.75, 8.8125, 8.875, 8.9375, 9.0, 9.0625, 9.125, 9.1875, 9.25, 9.3125, 9.375, 9.4375, 9.5],
 [6.5, 6.5625, 6.625, 6.6875, 6.75, 6.8125, 6.875, 6.9375, 7.0, 7.0625, 7.125, 7.1875, 7.25, 7.3125, 7.375, 7.4375, 7.5, 7.5625, 7.625, 7.6875, 7.75, 7.8125, 7.875, 7.9375, 8.0, 8.0625, 8.125, 8.1875, 8.25, 8.3125, 8.375, 8.4375, 8.5, 8.5625, 8.625, 8.6875, 8.75, 8.8125, 8.875, 8.9375, 9.0, 9.0625, 9.125, 9.1875, 9.25, 9.3125, 9.375, 9.4375, 9.5],
 [13.0, 13.125, 13.25, 13.375, 13.5, 13.625, 13.75, 13.875, 14.0, 14.125, 14.25, 14.375, 14.5, 14.625, 14.75, 14.875, 15.0, 15.125, 15.25, 15.375, 15.5, 15.625, 15.75, 15.875, 16.0, 16.125, 16.25, 16.375, 16.5, 16.625, 16.75, 16.875, 17.0, 17.125, 17.25, 17.375, 17.5, 17.625, 17.75, 17.875, 18.0, 18.125, 18.25, 18.375, 18.5, 18.625, 18.75, 18.875, 19],
 [13.0, 13.125, 13.25, 13.375, 13.5, 13.625, 13.75, 13.875, 14.0, 14.125, 14.25, 14.375, 14.5, 14.625, 14.75, 14.875, 15.0, 15.125, 15.25, 15.375, 15.5, 15.625, 15.75, 15.875, 16.0, 16.125, 16.25, 16.375, 16.5, 16.625, 16.75, 16.875, 17.0, 17.125, 17.25, 17.375, 17.5, 17.625, 17.75, 17.875, 18.0, 18.125, 18.25, 18.375, 18.5, 18.625, 18.75, 18.875, 19],
 [13.0, 13.125, 13.25, 13.375, 13.5, 13.625, 13.75, 13.875, 14.0, 14.125, 14.25, 14.375, 14.5, 14.625, 14.75, 14.875, 15.0, 15.125, 15.25, 15.375, 15.5, 15.625, 15.75, 15.875, 16.0, 16.25, 16.5, 16.75, 17.0, 17.25, 17.5, 17.75, 18.0, 18.25, 18.5, 18.75, 19.0, 19.25, 19.5, 19.75, 20.0, 20.25, 20.5, 20.75, 21.0, 21.25, 21.5, 21.75, 22],
 [30.0, 30.25, 30.5, 30.75, 31.0, 31.25, 31.5, 31.75, 32.0, 32.125, 32.25, 32.375, 32.5, 32.625, 32.75, 32.875, 33.0, 33.125, 33.25, 33.375, 33.5, 33.625, 33.75, 33.875, 34.0, 34.125, 34.25, 34.375, 34.5, 34.625, 34.75, 34.875, 35.0, 35.125, 35.25, 35.375, 35.5, 35.625, 35.75, 35.875, 36.0, 36.125, 36.25, 36.375, 36.5, 36.625, 36.75, 36.875, 37]
]


def img2patch(x, h, w, stride):
    size = x.size()
    x_tmp = x[:, :, 0:h, 0:w]
    for i in range(0, size[2], stride):
        for j in range(0, size[3], stride):
            x_tmp = torch.cat((x_tmp, x[:, :, i:i+h, j:j+w]), dim=0)
    return x_tmp[size[0]::, :, :, :]


# x -> [num_patch, 3, h, w]
def patch2img(x, img_h, img_w):
    size = x.size()
    img = torch.zeros(1, 3, img_h, img_w).cuda()
    k = 0
    for i in range(img_h // size[2]):
        for j in range(img_w // size[3]):
            img[:, :, i*size[2]:(i+1)*size[2], j*size[3]:(j+1)*size[3]] = x[k:k+1, :, :, :]
            k = k + 1
    return img


def img2patch_padding(x, h, w, stride, padding):
    size = x.size()
    x_tmp = x[:, :, 0:h, 0:w]
    for i in range(0, size[2]-2*padding, stride):
        for j in range(0, size[3]-2*padding, stride):
            x_tmp = torch.cat((x_tmp, x[:, :, i:i+h, j:j+w]), dim=0)
    return x_tmp[size[0]::, :, :, :]


def rgb2yuv(x):
    convert_mat = np.array([[0.299, 0.587, 0.114],
                            [-0.169, -0.331, 0.499],
                            [0.499, -0.418, -0.0813]], dtype=np.float32)

    y = x[:, 0:1, :, :] * convert_mat[0, 0] +\
        x[:, 1:2, :, :] * convert_mat[0, 1] +\
        x[:, 2:3, :, :] * convert_mat[0, 2]

    u = x[:, 0:1, :, :] * convert_mat[1, 0] +\
        x[:, 1:2, :, :] * convert_mat[1, 1] +\
        x[:, 2:3, :, :] * convert_mat[1, 2] + 128.

    v = x[:, 0:1, :, :] * convert_mat[2, 0] +\
        x[:, 1:2, :, :] * convert_mat[2, 1] +\
        x[:, 2:3, :, :] * convert_mat[2, 2] + 128.
    return torch.cat((y, u, v), dim=1)


def yuv2rgb(x):
    inverse_convert_mat = np.array([[1.0, 0.0, 1.402],
                                    [1.0, -0.344, -0.714],
                                    [1.0, 1.772, 0.0]], dtype=np.float32)
    r = x[:, 0:1, :, :] * inverse_convert_mat[0, 0] +\
        (x[:, 1:2, :, :] - 128.) * inverse_convert_mat[0, 1] +\
        (x[:, 2:3, :, :] - 128.) * inverse_convert_mat[0, 2]
    g = x[:, 0:1, :, :] * inverse_convert_mat[1, 0] +\
        (x[:, 1:2, :, :] - 128.) * inverse_convert_mat[1, 1] +\
        (x[:, 2:3, :, :] - 128.) * inverse_convert_mat[1, 2]
    b = x[:, 0:1, :, :] * inverse_convert_mat[2, 0] +\
        (x[:, 1:2, :, :] - 128.) * inverse_convert_mat[2, 1] +\
        (x[:, 2:3, :, :] - 128.) * inverse_convert_mat[2, 2]
    return torch.cat((r, g, b), dim=1)


def find_min_and_max(LL, HL_list, LH_list, HH_list):

    min_v = [[1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000.],
             [1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000.],
             [1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000., 1000000.]]
    max_v = [[-1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000.],
             [-1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000.],
             [-1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000., -1000000.]]

    for channel_idx in range(3):
        tmp = LL[0, channel_idx, :, :]
        min_tmp = torch.min(tmp).item()
        max_tmp = torch.max(tmp).item()
        if min_tmp < min_v[channel_idx][0]:
            min_v[channel_idx][0] = min_tmp
        if max_tmp > max_v[channel_idx][0]:
            max_v[channel_idx][0] = max_tmp

        for s_j in range(4):
            s_i = 4 - 1 - s_j
            tmp = HL_list[s_i][0, channel_idx, :, :]
            min_tmp = torch.min(tmp).item()
            max_tmp = torch.max(tmp).item()
            if min_tmp < min_v[channel_idx][3 * s_i + 1]:
                min_v[channel_idx][3 * s_i + 1] = min_tmp
            if max_tmp > max_v[channel_idx][3 * s_i + 1]:
                max_v[channel_idx][3 * s_i + 1] = max_tmp

            tmp = LH_list[s_i][0, channel_idx, :, :]
            min_tmp = torch.min(tmp).item()
            max_tmp = torch.max(tmp).item()
            if min_tmp < min_v[channel_idx][3 * s_i + 2]:
                min_v[channel_idx][3 * s_i + 2] = min_tmp
            if max_tmp > max_v[channel_idx][3 * s_i + 2]:
                max_v[channel_idx][3 * s_i + 2] = max_tmp

            tmp = HH_list[s_i][0, channel_idx, :, :]
            min_tmp = torch.min(tmp).item()
            max_tmp = torch.max(tmp).item()
            if min_tmp < min_v[channel_idx][3 * s_i + 3]:
                min_v[channel_idx][3 * s_i + 3] = min_tmp
            if max_tmp > max_v[channel_idx][3 * s_i + 3]:
                max_v[channel_idx][3 * s_i + 3] = max_tmp
    min_v = (np.array(min_v)).astype(np.int)
    max_v = (np.array(max_v)).astype(np.int)
    return min_v, max_v
